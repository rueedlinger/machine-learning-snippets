{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Binary Classification (scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this __Machine Learing Snippet__ we use scikit-learn (http://scikit-learn.org/) and ebooks from Project Gutenberg (https://www.gutenberg.org/) to create text binary classifier, which can classify German and English text.\n",
    "\n",
    "For our snippet we use the following ebooks:\n",
    "- Alice's Adventures in Wonderland by Lewis Carroll (English), https://www.gutenberg.org/ebooks/28885\n",
    "- Alice's Abenteuer im Wunderland by Lewis Carroll (German), https://www.gutenberg.org/ebooks/19778\n",
    "\n",
    "__Note:__\n",
    "The eBooks are for the use of anyone anywhere at no cost and with\n",
    "almost no restrictions whatsoever.  You may copy it, give it away or\n",
    "re-use it under the terms of the Project Gutenberg License included\n",
    "with this eBook or online at www.gutenberg.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Prepare the English and German text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens (german) 24934\n",
      "tokens (english) 26678\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt_german = open('data/pg19778.txt', 'r').read()\n",
    "txt_english = open('data/pg28885.txt', 'r').read()\n",
    "\n",
    "feat_german = txt_german[5000: len(txt_german) - 20000].lower().strip().split()\n",
    "feat_english = txt_english[5000: len(txt_english) - 20000].lower().strip().split()\n",
    "\n",
    "def remove_special_chars(x):\n",
    "    \n",
    "    chars = ['_', '(', ')', '*', '\"', '[', ']', '?', '!', ',', '.', '»', '«', ':', ';']\n",
    "    for c in chars:\n",
    "        x = x.replace(c, '')\n",
    "    \n",
    "    # remove numbers\n",
    "    x = re.sub('\\d', '', x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "feat_english = [remove_special_chars(x) for x in feat_english]\n",
    "feat_german = [remove_special_chars(x) for x in feat_german]\n",
    "\n",
    "print('tokens (german)', len(feat_german))\n",
    "print('tokens (english)', len(feat_english))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "Try to cut off the header and footer of the ebook. We use fixed values, this is not precise but will do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 133\n",
      "german 24934\n",
      "english 26678\n",
      "nun dinah sage die wahrheit hast du je einen spatzen gefressen da mit einem male plump plump kam sie auf einen haufen trocknes laub und reisig zu liegen -- und der fall war aus alice hatte sich gar nicht weh gethan sie sprang sogleich auf und sah in die höhe aber es war dunkel über ihr vor ihr lag ein zweiter langer gang und sie konnte noch eben das weiße kaninchen darin entlang laufen sehen es war kein augenblick zu verlieren fort rannte alice wie der wind und hörte es gerade noch sagen als es um eine ecke bog o ohren und schnurrbart wie spät es ist sie war dicht hinter ihm aber als sie um die ecke bog da war das kaninchen nicht mehr zu sehen sie befand sich in einem langen niedrigen corridor der durch eine reihe lampen erleuchtet war die von der decke herabhingen zu beiden seiten des corridors waren thüren aber sie waren alle verschlossen alice versuchte jede thür erst auf einer seite dann auf der andern endlich ging sie traurig in der mitte entlang überlegend wie sie je heraus kommen könnte plötzlich stand sie vor einem kleinen dreibeinigen tische ganz von dickem glas es war\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_text_sample(x):\n",
    "    data = []\n",
    "    text = []\n",
    "    for i, f in enumerate(x):\n",
    "        text.append(f)\n",
    "        if i % 200 == 0 and i != 0:\n",
    "            data.append(' '.join(text))\n",
    "            text = []\n",
    "    return data\n",
    "    \n",
    "\n",
    "print('len', len(data))\n",
    "\n",
    "\n",
    "print('german', len(feat_german))\n",
    "print('english', len(feat_english))\n",
    "\n",
    "\n",
    "print(create_text_sample(feat_german)[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
