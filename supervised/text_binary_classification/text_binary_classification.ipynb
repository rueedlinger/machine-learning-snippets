{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Binary Classification (scikit-learn) with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this __Machine Learing Snippet__ we use scikit-learn (http://scikit-learn.org/) and ebooks from Project Gutenberg (https://www.gutenberg.org/) to create text binary classifier, which can classify German and English text.\n",
    "\n",
    "For our snippet we use the following ebooks:\n",
    "- Alice's Adventures in Wonderland by Lewis Carroll (English), https://www.gutenberg.org/ebooks/28885\n",
    "- Alice's Abenteuer im Wunderland by Lewis Carroll (German), https://www.gutenberg.org/ebooks/19778\n",
    "\n",
    "__Note:__\n",
    "The eBooks are for the use of anyone anywhere at no cost and with\n",
    "almost no restrictions whatsoever.  You may copy it, give it away or\n",
    "re-use it under the terms of the Project Gutenberg License included\n",
    "with this eBook or online at www.gutenberg.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Prepare the English and German text. Try to cut off the header and footer of the ebook. We use fixed values, this is not precise but will do the job.\n",
    "- cut off header / footer\n",
    "- convert to lowercase\n",
    "- tokenize (separated by space)\n",
    "- remove special chars\n",
    "- remove numbers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens (german) 24934\n",
      "tokens (english) 26678\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt_german = open('data/pg19778.txt', 'r').read()\n",
    "txt_english = open('data/pg28885.txt', 'r').read()\n",
    "\n",
    "feat_german = txt_german[5000: len(txt_german) - 20000].lower().strip().split()\n",
    "feat_english = txt_english[5000: len(txt_english) - 20000].lower().strip().split()\n",
    "\n",
    "def remove_special_chars(x):\n",
    "    \n",
    "    chars = ['_', '(', ')', '*', '\"', '[', ']', '?', '!', ',', '.', '»', '«', ':', ';']\n",
    "    for c in chars:\n",
    "        x = x.replace(c, '')\n",
    "    \n",
    "    # remove numbers\n",
    "    x = re.sub('\\d', '', x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "feat_english = [remove_special_chars(x) for x in feat_english]\n",
    "feat_german = [remove_special_chars(x) for x in feat_german]\n",
    "\n",
    "print('tokens (german)', len(feat_german))\n",
    "print('tokens (english)', len(feat_english))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "Create text samples with 200 tokens (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples (german) 124\n",
      "samples (english) 133\n"
     ]
    }
   ],
   "source": [
    "def create_text_sample(x):\n",
    "    max_tokens = 200\n",
    "    data = []\n",
    "    text = []\n",
    "    for i, f in enumerate(x):\n",
    "        text.append(f)\n",
    "        if i % max_tokens == 0 and i != 0:\n",
    "            data.append(' '.join(text))\n",
    "            text = []\n",
    "    return data\n",
    "    \n",
    "\n",
    "sample_german = create_text_sample(feat_german)\n",
    "sample_english = create_text_sample(feat_english)\n",
    "\n",
    "print('samples (german)', len(sample_german))\n",
    "print('samples (english)', len(sample_english))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the text samples to train our binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sample:\n",
      "------------------\n",
      " an unusually large saucepan flew close by it and very nearly carried it off  it grunted again so violently that she looked down into its face in some alarm  a mad tea-party  the queen turned angrily away from him and said to the knave turn them over  the queen never left off quarrelling with the other players and shouting off with his head or off with her head  the mock turtle drew a long breath and said that's very curious  who stole the tarts  at this the whole pack rose up into the air and came flying down upon her  chapter i sidenote down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank and of having nothing to do once or twice she had peeped into the book her sister was reading but it had no pictures or conversations in it and what is the use of a book thought alice without pictures or conversations so she was considering in her own mind as well as she could for the hot day made her feel very sleepy and stupid whether the pleasure of making\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "print('English sample:\\n------------------')\n",
    "print(sample_english[0])\n",
    "print('------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
